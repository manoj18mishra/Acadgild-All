{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student’s t-Test\n",
    "\n",
    "The Student’s t-Test is a statistical hypothesis test for testing whether two samples are expected to have been drawn from the same population.\n",
    "\n",
    "Assumptions :\n",
    "\n",
    "* In working with the means of the samples, the test assumes that both samples were drawn from a Gaussian distribution. \n",
    "* The test also assumes that the samples have the same variance, and the same size, although there are corrections to the test if these assumptions do not hold. If you have two independent samples but you do not know that they have equal variance, you can use `Welch's t-test`.\n",
    "\n",
    "There are two main versions of Student’s t-test:\n",
    "\n",
    "**Independent Samples** The case where the two samples are unrelated.\n",
    "\n",
    "**Dependent Samples** The case where the samples are related, such as repeated measures on the same population. Also called a paired test.\n",
    "\n",
    "Both the independent and the dependent Student’s t-tests are available in Python via the ttest_ind() and ttest_rel() SciPy functions respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student’s t-Test for Independent Samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# t-test for independent samples\n",
    "from math import sqrt\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from scipy.stats import sem\n",
    "from scipy.stats import t\n",
    " \n",
    "# function for calculating the t-test for two independent samples\n",
    "def independent_ttest(data1, data2, alpha):\n",
    "\t# calculate means\n",
    "\tmean1, mean2 = mean(data1), mean(data2)\n",
    "\t# calculate standard errors\n",
    "\tse1, se2 = sem(data1), sem(data2)\n",
    "\t# standard error on the difference between the samples\n",
    "\tsed = sqrt(se1**2.0 + se2**2.0)\n",
    "\t# calculate the t statistic\n",
    "\tt_stat = (mean1 - mean2) / sed\n",
    "\t# degrees of freedom\n",
    "\tdf = len(data1) + len(data2) - 2\n",
    "\t# calculate the critical value\n",
    "\tcv = t.ppf(1.0 - alpha, df)\n",
    "\t# calculate the p-value\n",
    "\tp = (1.0 - t.cdf(abs(t_stat), df)) * 2.0\n",
    "\t# return everything\n",
    "\treturn t_stat, df, cv, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=-2.262, df=198, cv=1.653, p=0.025\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate two independent samples\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 51\n",
    "# calculate the t test\n",
    "alpha = 0.05\n",
    "t_stat, df, cv, p = independent_ttest(data1, data2, alpha)\n",
    "print('t=%.3f, df=%d, cv=%.3f, p=%.3f' % (t_stat, df, cv, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply our own implementation on the same data, using the function defined in the previous section.\n",
    "\n",
    "The function will return a t-statistic value and a critical value. We can use the critical value to interpret the t statistic to see if the finding of the test is significant and that indeed the means are different as we expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis that the means are equal.\n",
      "Reject the null hypothesis that the means are equal.\n"
     ]
    }
   ],
   "source": [
    "# interpret via critical value\n",
    "if abs(t_stat) <= cv:\n",
    "\tprint('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    "\tprint('Reject the null hypothesis that the means are equal.')\n",
    "# interpret via p-value\n",
    "if p > alpha:\n",
    "\tprint('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    "\tprint('Reject the null hypothesis that the means are equal.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student’s t-Test for Dependent Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-test for dependent samples\n",
    "from math import sqrt\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from scipy.stats import t\n",
    "\n",
    "# function for calculating the t-test for two dependent samples\n",
    "def dependent_ttest(data1, data2, alpha):\n",
    "\t# calculate means\n",
    "\tmean1, mean2 = mean(data1), mean(data2)\n",
    "\t# number of paired samples\n",
    "\tn = len(data1)\n",
    "\t# sum squared difference between observations\n",
    "\td1 = sum([(data1[i]-data2[i])**2 for i in range(n)])\n",
    "\t# sum difference between observations\n",
    "\td2 = sum([data1[i]-data2[i] for i in range(n)])\n",
    "\t# standard deviation of the difference between means\n",
    "\tsd = sqrt((d1 - (d2**2 / n)) / (n - 1))\n",
    "\t# standard error of the difference between the means\n",
    "\tsed = sd / sqrt(n)\n",
    "\t# calculate the t statistic\n",
    "\tt_stat = (mean1 - mean2) / sed\n",
    "\t# degrees of freedom\n",
    "\tdf = n - 1\n",
    "\t# calculate the critical value\n",
    "\tcv = t.ppf(1.0 - alpha, df)\n",
    "\t# calculate the p-value\n",
    "\tp = (1.0 - t.cdf(abs(t_stat), df)) * 2.0\n",
    "\t# return everything\n",
    "\treturn t_stat, df, cv, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=-2.372, df=99, cv=1.660, p=0.020\n"
     ]
    }
   ],
   "source": [
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate two independent samples (pretend they are dependent)\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 51\n",
    "\n",
    "# calculate the t test\n",
    "alpha = 0.05\n",
    "t_stat, df, cv, p = dependent_ttest(data1, data2, alpha)\n",
    "print('t=%.3f, df=%d, cv=%.3f, p=%.3f' % (t_stat, df, cv, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis that the means are equal.\n",
      "Reject the null hypothesis that the means are equal.\n"
     ]
    }
   ],
   "source": [
    "# interpret via critical value\n",
    "if abs(t_stat) <= cv:\n",
    "\tprint('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    "\tprint('Reject the null hypothesis that the means are equal.')\n",
    "# interpret via p-value\n",
    "if p > alpha:\n",
    "\tprint('Accept null hypothesis that the means are equal.')\n",
    "else:\n",
    "\tprint('Reject the null hypothesis that the means are equal.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### One Sample T Test\n",
    "\n",
    "A One Sample T-Test is a statistical test used to evaluate the null hypothesis that the mean  of a 1D sample dataset of independant observations is equal to the true mean  of the population from which the data is sampled. In other words, our null hypothesis is that\n",
    "For our T-test, we will be using a significance level of 0.05. On the matter of doing ethical science, it is good practice to always state the chosen significance level for a given test before actually conducting the test. This is meant to ensure that the analyst does not modify the significance level for the purpose of achieving a desired outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Ttest_indResult(statistic=0.26833823296238857, pvalue=0.788494433695651),\n",
       " Ttest_indResult(statistic=0.26833823296238857, pvalue=0.7884945274950106))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test with sample with identical means:\n",
    "\n",
    "\n",
    "rvs1 = stats.norm.rvs(loc=5,scale=10,size=500)\n",
    "rvs2 = stats.norm.rvs(loc=5,scale=10,size=500)\n",
    "\n",
    "## it returns a tuple with the t-statistic & the p-value\n",
    "stats.ttest_ind(rvs1,rvs2),stats.ttest_ind(rvs1,rvs2, equal_var = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Ttest_indResult(statistic=-0.46580283298287956, pvalue=0.6414582741343561),\n",
       " Ttest_indResult(statistic=-0.46580283298287956, pvalue=0.6414964624656874))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ttest_ind underestimates p for unequal variances:\n",
    "\n",
    "\n",
    "rvs3 = stats.norm.rvs(loc=5, scale=20, size=500)\n",
    "stats.ttest_ind(rvs1, rvs3),stats.ttest_ind(rvs1, rvs3, equal_var = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Ttest_indResult(statistic=-0.9988253944278285, pvalue=0.3182832709103878),\n",
       " Ttest_indResult(statistic=-0.6971257058465435, pvalue=0.4871692772540187))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## When n1 != n2, the equal variance t-statistic is no longer equal to the unequal variance t-statistic:\n",
    "\n",
    "\n",
    "rvs4 = stats.norm.rvs(loc=5, scale=20, size=100)\n",
    "stats.ttest_ind(rvs1, rvs4),stats.ttest_ind(rvs1, rvs4, equal_var = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Ttest_indResult(statistic=-1.467966985449067, pvalue=0.14263895620529113),\n",
       " Ttest_indResult(statistic=-0.9436597361713308, pvalue=0.3474417033479409))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## T-test with different means, variance, and n:\n",
    "\n",
    "\n",
    "rvs5 = stats.norm.rvs(loc=8, scale=20, size=100)\n",
    "stats.ttest_ind(rvs1, rvs5),stats.ttest_ind(rvs1, rvs5, equal_var = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
